#' Sythetic reads generator for genetic variants
#' 
#' There are following steps to generate the simulated reads counts for variants
#' in single cells:
#' 1) given the clonal genotype and the clonal prevalence, the genotypes of 
#' cells will be generated following a multinormial distribution. 
#' 2) given the distribution of reads coverage, e.g., a set of read coverage 
#' from real data, the total reads of each variant will be generated by random 
#' sampling.
#' 3) the allelic frequence of each variant will be generated by following a 
#' beta distribution.
#' 4) Given the genotype of a cell, if the mutation exists in a cell, the 
#' alteration read counts will be generated by a binomial distribution, 
#' papramitized the allelic frequency, sampled from step 3.
#' 5) Given the genotype of a cell, if the mutation doesnot exist in a cell, 
#' the alteration read counts will be genenrated by a binomial distribution,
#' paramerized by the technical error rate.
#' 6) Given the missing rate, NA value will be given to mask the read counts
#' 
#' @param D A vector of integers. Sequencing depth for variants
#' @param C A matrix of binary values. The clone-variant configuration, whcih 
#' encodes the phylogenetic tree structure. This is the output Z of Canopy
#' @param Psi A vector of float. The fractions of each clone, output P of Canopy
sim_read_count <- function(C, D, Psi=NULL, means=c(0.03, 0.45), 
                           vars=c(1.0, 0.3), missing_rate=0.9, cell_num=300){
  M <- cell_num   #number of cells
  K <- dim(C)[2]  #number of clones
  N <- dim(C)[1]  #number of variants
  
  shape1s <- means / vars
  shape2s <- 1.0 /vars - shape1s
  
  # genotype for cells H_sim, and clone labels I_sim
  if(is.null(Psi)){
    Psi <- rep(1/K, K)
  }
  I_sim <- rmultinom(M, 1, prob=Psi)
  H_sim <- C %*% I_sim
  
  # generate p, D and A
  p_sim <- matrix(0, N, 2)
  A_sim <- matrix(NA, N, M)
  D_sim <- matrix(NA, N, M)
  D_non_0 <- D[which(D>0)]
  for (i in seq_len(N)){
    p_sim[i,1] <- rbeta(1, shape1s[1], shape2s[1])
    p_sim[i,2] <- rbeta(1, shape1s[2], shape2s[2])
    for(j in seq_len(M)){
      is_mising <- rbinom(1, 1, missing_rate)
      if (!is_mising){
        D_sim[i,j] = sample(D_non_0, 1, replace = TRUE)
        A_sim[i,j] = rbinom(1, D_sim[i,j], p_sim[i,H_sim[i,j]+1])
      }
    }
  }
  return_list <- list("A_sim"=A_sim, "D_sim"=D_sim, "I_sim"=t(I_sim), 
                      "H_sim"=H_sim, "p_sim"=p_sim)
  return_list
}


assign_score <- function(true_assign, prob_assign, min_prob_gap=0.25){
  M <- dim(true_assign)[1]
  K <- dim(true_assign)[2]
  
  able_assigns <- rep(FALSE, M)
  corr_assigns <- rep(FALSE, M)
  for (j in seq_len(M)){
    prob_sorted <- sort(prob_assign[j,], decreasing = TRUE)
    if ((prob_sorted[1] - prob_sorted[2]) >= min_prob_gap){
      able_assigns[j] = TRUE
    }
    # idx <- which(prob_sorted[1] == prob_assign[j,])
    # if (sum(true_assign[j,idx]) > 0){
    #   corr_assigns[j] = TRUE
    # }
    if(which.max(true_assign[j,]) == which.max(prob_assign[j,])){
      corr_assigns[j] = TRUE
    }
  }
  #mean(corr_assigns), mean(able_assigns), mean(corr_assigns[able_assigns])
  return_list <- list("able_assigns"=able_assigns, "corr_assigns"=corr_assigns)
  return_list
}


get_error_rate <- function(H_sim, A_sim, threshold=1){
  N <- dim(A_sim)[1]
  M <- dim(A_sim)[1]
  error_rate <- matrix(NA, N, 2)
  for (i in seq_len(N)){
    idx1 <- as.logical((!is.na(A_sim[i,])) * (H_sim[i,]==0))
    idx2 <- as.logical((!is.na(A_sim[i,])) * (H_sim[i,]==1))
    if (sum(idx1) > 0){
      error_rate[i,1] <- mean(A_sim[i,idx1] >= threshold)
    }
    if (sum(idx2) > 0){
      error_rate[i,2] <- mean(A_sim[i,idx2] < threshold)
    }
  }
  
  error_rate_mean <- rep(NA, 2)
  idx1 <- as.logical((!is.na(A_sim)) * (H_sim==0))
  idx2 <- as.logical((!is.na(A_sim)) * (H_sim==1))
  error_rate_mean[1] <- mean(A_sim[idx1] >= threshold)
  error_rate_mean[2] <- mean(A_sim[idx2] >= threshold)
  
  return_list <- list("error_rate"=error_rate, 
                      "error_rate_mean"=error_rate_mean)
  return_list
}
